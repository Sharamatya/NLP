{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 379
    },
    "id": "djRU7OtPjIqO",
    "outputId": "d8b0b084-1e14-4658-889a-d421d0c249f4"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')  # \"error\", \"ignore\", \"always\", \"default\", \"module\" or \"once\"\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize,sent_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "import pandas as pd\n",
    "import scipy.stats\n",
    "\n",
    "import sklearn\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.model_selection import cross_val_score, RandomizedSearchCV\n",
    "\n",
    "import sklearn_crfsuite\n",
    "from sklearn_crfsuite import CRF\n",
    "from sklearn_crfsuite import scorers\n",
    "from sklearn_crfsuite import metrics\n",
    "\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VhGm0DUrjc7k"
   },
   "source": [
    "# Preprocessing\n",
    "The format of file is not compatible with pyconllu reader library, thus we adopt a different implementation to read the file and parse it: \n",
    "- Open the file\n",
    "- Read lines and break whenever a NULL tag is encountered\n",
    "- We use `strip()` to remove all unnecessary spaces from words and tags\n",
    "- We use `split()` to parse and divide lines w.r.t the given splitter :\n",
    "    - In case of Train data splitter = ','\n",
    "    - In case of Test data splitter = '\\t'\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preproc(fname, fg):\n",
    "    set_tags, tags = list(), list()\n",
    "    set_sents, sents = list(), list()\n",
    "    fp = open(fname, encoding=\"utf-8\")\n",
    "    lines = fp.readlines() # reading data rowise\n",
    "    \n",
    "    for line in lines[1:]: # iterate over all rows\n",
    "        if fg == 1: # in case of test data\n",
    "            index, word, tag = line.split(\"\\t\") # split on tabs\n",
    "            index = index.strip()\n",
    "            word = word.strip()\n",
    "            tag = tag.strip()\n",
    "        if fg == 0: # in case of test data\n",
    "            index, word, tag = line.strip().split(',') # split on commas\n",
    "        if len(tag) > 0:\n",
    "            if tag == \"COMMA\":\n",
    "                sents.append(\",\")\n",
    "                tags.append(\"COMMA\")\n",
    "            else:\n",
    "                sents.append(word)\n",
    "                tags.append(tag)\n",
    "        else: # if a newline is encountered\n",
    "            set_sents.append(sents) # append current list to main list\n",
    "            set_tags.append(tags)\n",
    "            sents, tags = list(), list() # reinitialize\n",
    "    return set_sents, set_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "JCOZDbUNzV_i",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# build train set and test set using preproc functions\n",
    "train_sents, train_tags = preproc(\"hi-ud-train.conllu\", 0)\n",
    "test_sents, test_tags = preproc(\"hi-ud-test.conllu\", 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# train_sents :  499\n",
      "            0      1\n",
      "0       yahAz   PRON\n",
      "1      lagane   VERB\n",
      "2        vAlA    ADP\n",
      "3        wIna    NUM\n",
      "4        xina   NOUN\n",
      "5          kA    ADP\n",
      "6      ijwimA   NOUN\n",
      "7        pUre    ADJ\n",
      "8        xeSa   NOUN\n",
      "9          ke    ADP\n",
      "10      logoM   NOUN\n",
      "11         ko    ADP\n",
      "12  AmaMwriwa    ADJ\n",
      "13     karawA   VERB\n",
      "14         hE    AUX\n",
      "15          .  PUNCT\n",
      "\n",
      "\n",
      "# test_sents :  99\n",
      "                  0      1\n",
      "0              1876  PROPN\n",
      "1               meM    ADP\n",
      "2              yaha    DET\n",
      "3             sWAna   NOUN\n",
      "4               eka    NUM\n",
      "5              bAra   NOUN\n",
      "6              Pira    ADV\n",
      "7           prakASa   NOUN\n",
      "8               meM    ADP\n",
      "9               AyA   VERB\n",
      "10              \",\"  PUNCT\n",
      "11             jaba   PRON\n",
      "12        wawkAlIna    ADJ\n",
      "13   purAwawvavewwA   NOUN\n",
      "14           lOYrda   NOUN\n",
      "15       karniMGama  PROPN\n",
      "16               ne    ADP\n",
      "17  mahAparinirvANa  PROPN\n",
      "18            mUrwi  PROPN\n",
      "19               kI    ADP\n",
      "20             Koja   NOUN\n",
      "21               kI   VERB\n",
      "22                .  PUNCT\n"
     ]
    }
   ],
   "source": [
    "# print some data \n",
    "print(\"# train_sents : \", len(train_sents))\n",
    "print(pd.DataFrame(list(zip(train_sents[5], train_tags[5]))))\n",
    "\n",
    "print(\"\\n\\n# test_sents : \", len(test_sents))\n",
    "print(pd.DataFrame(list(zip(test_sents[5], test_tags[5])) ) )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Extraction \n",
    "\n",
    "| S. No. | Feature | Convinience | Implementation |\n",
    "|--------|---------|-------------|----------------|\n",
    "|2| LowerCase| Reduces the ambiguity of case in words | `word.lower()`|\n",
    "|3| IsUpperCase| Check if the word is all upper case, can check for emphasis in words | `word.isupper()`|\n",
    "|4| IsTittleCase| Check if the word is all upper case, can check for emphasis in words | `word.istitle()`|\n",
    "|5| IsDigit| Filtering digits adds in details to words and reduces chances of certain POS numerics can't be assigned | `word.isdigit()`|\n",
    "|6| Suffix[-3:]| Extracting last 3 letters as suffix as most hindi suffixes involve 2 or 3 letters | `word[-3:]`|       \n",
    "|7| Suffix[-2:]| -do- | `word[-2:]`|\n",
    "|8| Prefix[3:]| Extracting first 3 letters as prefix as most hindi prefixes involve 2 or 3 letters | `word[:3]`|        \n",
    "|9| Prefix[2:]| -do- | `word[:2]`|\n",
    "|10| Stem | Extracting Stem from the word helps in removing common prefixes and suffixes to get root form of words reducing possible vocabulary | `ps.stem(word)`|\n",
    "|11| Lemma | Extracting Lemma from the word helps in  reducing possible vocabulary size and reduces ambiguity among words with same base meaning | `ws.lemmatize(word)`|\n",
    "|12| -1_word | Previous word improves results by introducing context | `sent[i-1]`|\n",
    "|13| -1_word_Lowercase | -do- | `sent[i-1].lower()`|\n",
    "|14| -1_word_istitlecase |-do-| `sent[i-1].istitle()`|\n",
    "|15| -1_word_isuppercase|-do-| `sent[i-1].isupper()`|\n",
    "|16| -1_word_Stem |-do-|`ps.stem(sent[i-1])`|\n",
    "|17| -1_word_Lemma |-do-|`ws.lemmatize(sent[i-1])` |\n",
    "|18| START |  True if the word is first word of sentence or begining of sentence | |\n",
    "|19| +1_word | Next word improves results by introducing context | `sent[i+1]`|\n",
    "|20| +1_word_Lowercase | -do- | `sent[i+1].lower()`|\n",
    "|21| +1_word_istitlecase |-do-| `sent[i+1].istitle()`|\n",
    "|22| +1_word_isuppercase|-do-| `sent[i+1].isupper()`|\n",
    "|23| +1_word_Stem |-do-|`ps.stem(sent[i+1])`|\n",
    "|24| +1_word_Lemma |-do-|`ws.lemmatize(sent[i+1])` |\n",
    "|25| END |  True if the word is last word of sentence or emd of sentence | |\n",
    "|26| -2_word|Next word improves results by introducing context | `sent[i-2]`|\n",
    "|27| NextToStart | True if the word is second word of sentence | |\n",
    "|28| -2_word|Next word improves results by introducing context | `sent[i+2]`|\n",
    "|29| PrevToEnd | True if the word is second last word of sentence | |\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "aFN5jb2L18xn"
   },
   "outputs": [],
   "source": [
    "ps = PorterStemmer()\n",
    "ws = WordNetLemmatizer()\n",
    "\n",
    "def extractFeatures(sent, tags, i):\n",
    "    word = sent[i]\n",
    "    postag = tags[i]\n",
    "\n",
    "    features = {\n",
    "        'bias': 1.0,\n",
    "        'LowerCase': word.lower(),\n",
    "        'IsUpperCase': word.isupper(),\n",
    "        'IsTittleCase': word.istitle(),\n",
    "        'IsDigit': word.isdigit(),\n",
    "        'Suffix[-3:]': word[-3:],\n",
    "        'Suffix[-2:]': word[-2:],\n",
    "        'Prefix[3:]': word[:3],\n",
    "        'Prefix[2:]': word[:2],\n",
    "        'Stem': ps.stem(word),\n",
    "        'Lemma' : ws.lemmatize(word),\n",
    "    }\n",
    "    if i > 0:\n",
    "        features.update({\n",
    "            '-1_word' : sent[i-1],\n",
    "#             '-1_word_isdigit()': sent[i-1].isdigit(),\n",
    "            '-1_word_Lowercase': sent[i-1].lower(),\n",
    "            '-1_word_istitlecase': sent[i-1].istitle(),\n",
    "            '-1_word_isuppercase': sent[i-1].isupper(),\n",
    "            '-1_word_Stem': ps.stem(sent[i-1]),\n",
    "            '-1_word_Lemma' : ws.lemmatize(sent[i-1]),\n",
    "        })\n",
    "    else:\n",
    "        features['START'] = True\n",
    "\n",
    "    if i < len(sent)-1:\n",
    "        features.update({\n",
    "            '+1:word' : sent[i+1],\n",
    "#             '+1_word_isdigit()': sent[i+1].isdigit(),\n",
    "            '+1:word_Lower': sent[i+1].lower(),\n",
    "            '+1:word_istitlecase': sent[i+1].istitle(),\n",
    "            '+1:word_isuppercase': sent[i+1].isupper(),\n",
    "            '+1_word_Stem': ps.stem(sent[i+1]),\n",
    "            '+1_word_Lemma' : ws.lemmatize(sent[i+1]),\n",
    "        })\n",
    "    else:\n",
    "        features['END'] = True\n",
    "    \n",
    "    if i > 1:\n",
    "        features.update({\n",
    "            '-2_word' : sent[i-2],\n",
    "#             '-2_word_isdigit()': sent[i-2].isdigit(),\n",
    "#             '-2_word_islower()': sent[i-2].lower(),\n",
    "#             '-2_word_istitle()': sent[i-2].istitle(),\n",
    "#             '-2_word_isupper()': sent[i-2].isupper(),\n",
    "#             '-2_word_Stem': ps.stem(sent[i-2]),\n",
    "#             '-2_word_Lemma' : ws.lemmatize(sent[i-2]),\n",
    "        })\n",
    "    else:\n",
    "        features['NextToStart'] = True\n",
    "\n",
    "    if i < len(sent)-2:\n",
    "        features.update({\n",
    "            '+2:word' : sent[i+2],\n",
    "# #             '+2_word_isdigit()': sent[i+1].isdigit(),\n",
    "#             '+2:word.lower()': sent[i+2].lower(),\n",
    "#             '+2:word.istitle()': sent[i+2].istitle(),\n",
    "#             '+2:word.isupper()': sent[i+2].isupper(),\n",
    "#             '+2_word_Stem': ps.stem(sent[i+2]),\n",
    "#             '+2_word_Lemma' : ws.lemmatize(sent[i+2]),\n",
    "        })\n",
    "    else:\n",
    "        features['PrevToEnd'] = True\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "aFN5jb2L18xn"
   },
   "outputs": [],
   "source": [
    "def sentFeat(sent, tags):\n",
    "    return [extractFeatures(sent, tags, i) for i in range(len(sent))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 104
    },
    "id": "e7rrnoFq2KXz",
    "outputId": "82af94f0-0dd5-4f93-f6cc-079e372921c7"
   },
   "outputs": [],
   "source": [
    "X_train = [sentFeat(train_sents[i], train_tags[i]) for i in range(len(train_sents))]\n",
    "y_train = train_tags #[sent2labels(s) for s in training_sentences]\n",
    "\n",
    "X_test = [sentFeat(test_sents[i], test_tags[i]) for i in range(len(test_sents))]\n",
    "y_test = test_tags #[sent2labels(s) for s in training_sentences]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 104
    },
    "id": "e7rrnoFq2KXz",
    "outputId": "82af94f0-0dd5-4f93-f6cc-079e372921c7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "499\n",
      "    bias  LowerCase  IsUpperCase  IsTittleCase  IsDigit Suffix[-3:]  \\\n",
      "0    1.0      yahaz        False         False    False         hAz   \n",
      "1    1.0     lagane        False         False    False         ane   \n",
      "2    1.0       vala        False         False    False         AlA   \n",
      "3    1.0       wina        False         False    False         Ina   \n",
      "4    1.0       xina        False         False    False         ina   \n",
      "5    1.0         ka        False         False    False          kA   \n",
      "6    1.0     ijwima        False         False    False         imA   \n",
      "7    1.0       pure        False         False    False         Ure   \n",
      "8    1.0       xesa        False         False    False         eSa   \n",
      "9    1.0         ke        False         False    False          ke   \n",
      "10   1.0      logom        False         False    False         goM   \n",
      "11   1.0         ko        False         False    False          ko   \n",
      "12   1.0  amamwriwa        False         False    False         iwa   \n",
      "13   1.0     karawa        False         False    False         awA   \n",
      "14   1.0         he        False         False    False          hE   \n",
      "15   1.0          .        False         False    False           .   \n",
      "\n",
      "   Suffix[-2:] Prefix[3:] Prefix[2:]       Stem  ...    +2:word    -1_word  \\\n",
      "0           Az        yah         ya      yahaz  ...       vAlA        NaN   \n",
      "1           ne        lag         la      lagan  ...       wIna      yahAz   \n",
      "2           lA        vAl         vA       vala  ...       xina     lagane   \n",
      "3           na        wIn         wI       wina  ...         kA       vAlA   \n",
      "4           na        xin         xi       xina  ...     ijwimA       wIna   \n",
      "5           kA         kA         kA         kA  ...       pUre       xina   \n",
      "6           mA        ijw         ij     ijwima  ...       xeSa         kA   \n",
      "7           re        pUr         pU       pure  ...         ke     ijwimA   \n",
      "8           Sa        xeS         xe       xesa  ...      logoM       pUre   \n",
      "9           ke         ke         ke         ke  ...         ko       xeSa   \n",
      "10          oM        log         lo      logom  ...  AmaMwriwa         ke   \n",
      "11          ko         ko         ko         ko  ...     karawA      logoM   \n",
      "12          wa        Ama         Am  amamwriwa  ...         hE         ko   \n",
      "13          wA        kar         ka     karawa  ...          .  AmaMwriwa   \n",
      "14          hE         hE         hE         hE  ...        NaN     karawA   \n",
      "15           .          .          .          .  ...        NaN         hE   \n",
      "\n",
      "   -1_word_Lowercase -1_word_istitlecase -1_word_isuppercase -1_word_Stem  \\\n",
      "0                NaN                 NaN                 NaN          NaN   \n",
      "1              yahaz               False               False        yahaz   \n",
      "2             lagane               False               False        lagan   \n",
      "3               vala               False               False         vala   \n",
      "4               wina               False               False         wina   \n",
      "5               xina               False               False         xina   \n",
      "6                 ka               False               False           kA   \n",
      "7             ijwima               False               False       ijwima   \n",
      "8               pure               False               False         pure   \n",
      "9               xesa               False               False         xesa   \n",
      "10                ke               False               False           ke   \n",
      "11             logom               False               False        logom   \n",
      "12                ko               False               False           ko   \n",
      "13         amamwriwa               False               False    amamwriwa   \n",
      "14            karawa               False               False       karawa   \n",
      "15                he               False               False           hE   \n",
      "\n",
      "   -1_word_Lemma    -2_word PrevToEnd   END  \n",
      "0            NaN        NaN       NaN   NaN  \n",
      "1          yahAz        NaN       NaN   NaN  \n",
      "2         lagane      yahAz       NaN   NaN  \n",
      "3           vAlA     lagane       NaN   NaN  \n",
      "4           wIna       vAlA       NaN   NaN  \n",
      "5           xina       wIna       NaN   NaN  \n",
      "6             kA       xina       NaN   NaN  \n",
      "7         ijwimA         kA       NaN   NaN  \n",
      "8           pUre     ijwimA       NaN   NaN  \n",
      "9           xeSa       pUre       NaN   NaN  \n",
      "10            ke       xeSa       NaN   NaN  \n",
      "11         logoM         ke       NaN   NaN  \n",
      "12            ko      logoM       NaN   NaN  \n",
      "13     AmaMwriwa         ko       NaN   NaN  \n",
      "14        karawA  AmaMwriwa      True   NaN  \n",
      "15            hE     karawA      True  True  \n",
      "\n",
      "[16 rows x 29 columns]\n",
      "['PRON', 'VERB', 'ADP', 'NUM', 'NOUN', 'ADP', 'NOUN', 'ADJ', 'NOUN', 'ADP', 'NOUN', 'ADP', 'ADJ', 'VERB', 'AUX', 'PUNCT'] \n",
      "\n",
      "99\n",
      "    bias        LowerCase  IsUpperCase  IsTittleCase  IsDigit Suffix[-3:]  \\\n",
      "0    1.0             1876        False         False     True         876   \n",
      "1    1.0              mem        False         False    False         meM   \n",
      "2    1.0             yaha        False         False    False         aha   \n",
      "3    1.0            swana        False         False    False         Ana   \n",
      "4    1.0              eka        False         False    False         eka   \n",
      "5    1.0             bara        False         False    False         Ara   \n",
      "6    1.0             pira        False          True    False         ira   \n",
      "7    1.0          prakasa        False         False    False         ASa   \n",
      "8    1.0              mem        False         False    False         meM   \n",
      "9    1.0              aya        False         False    False         AyA   \n",
      "10   1.0              \",\"        False         False    False         \",\"   \n",
      "11   1.0             jaba        False         False    False         aba   \n",
      "12   1.0        wawkalina        False         False    False         Ina   \n",
      "13   1.0   purawawvavewwa        False         False    False         wwA   \n",
      "14   1.0           loyrda        False         False    False         rda   \n",
      "15   1.0       karnimgama        False         False    False         ama   \n",
      "16   1.0               ne        False         False    False          ne   \n",
      "17   1.0  mahaparinirvana        False         False    False         ANa   \n",
      "18   1.0            murwi        False         False    False         rwi   \n",
      "19   1.0               ki        False         False    False          kI   \n",
      "20   1.0             koja        False          True    False         oja   \n",
      "21   1.0               ki        False         False    False          kI   \n",
      "22   1.0                .        False         False    False           .   \n",
      "\n",
      "   Suffix[-2:] Prefix[3:] Prefix[2:]             Stem  ...          +2:word  \\\n",
      "0           76        187         18             1876  ...             yaha   \n",
      "1           eM        meM         me              mem  ...            sWAna   \n",
      "2           ha        yah         ya             yaha  ...              eka   \n",
      "3           na        sWA         sW            swana  ...             bAra   \n",
      "4           ka        eka         ek              eka  ...             Pira   \n",
      "5           ra        bAr         bA             bara  ...          prakASa   \n",
      "6           ra        Pir         Pi             pira  ...              meM   \n",
      "7           Sa        pra         pr          prakasa  ...              AyA   \n",
      "8           eM        meM         me              mem  ...              \",\"   \n",
      "9           yA        AyA         Ay              aya  ...             jaba   \n",
      "10          ,\"        \",\"         \",              \",\"  ...        wawkAlIna   \n",
      "11          ba        jab         ja             jaba  ...   purAwawvavewwA   \n",
      "12          na        waw         wa        wawkalina  ...           lOYrda   \n",
      "13          wA        pur         pu   purawawvavewwa  ...       karniMGama   \n",
      "14          da        lOY         lO           loyrda  ...               ne   \n",
      "15          ma        kar         ka       karnimgama  ...  mahAparinirvANa   \n",
      "16          ne         ne         ne               ne  ...            mUrwi   \n",
      "17          Na        mah         ma  mahaparinirvana  ...               kI   \n",
      "18          wi        mUr         mU            murwi  ...             Koja   \n",
      "19          kI         kI         kI               kI  ...               kI   \n",
      "20          ja        Koj         Ko             koja  ...                .   \n",
      "21          kI         kI         kI               kI  ...              NaN   \n",
      "22           .          .          .                .  ...              NaN   \n",
      "\n",
      "            -1_word -1_word_Lowercase -1_word_istitlecase -1_word_isuppercase  \\\n",
      "0               NaN               NaN                 NaN                 NaN   \n",
      "1              1876              1876               False               False   \n",
      "2               meM               mem               False               False   \n",
      "3              yaha              yaha               False               False   \n",
      "4             sWAna             swana               False               False   \n",
      "5               eka               eka               False               False   \n",
      "6              bAra              bara               False               False   \n",
      "7              Pira              pira                True               False   \n",
      "8           prakASa           prakasa               False               False   \n",
      "9               meM               mem               False               False   \n",
      "10              AyA               aya               False               False   \n",
      "11              \",\"               \",\"               False               False   \n",
      "12             jaba              jaba               False               False   \n",
      "13        wawkAlIna         wawkalina               False               False   \n",
      "14   purAwawvavewwA    purawawvavewwa               False               False   \n",
      "15           lOYrda            loyrda               False               False   \n",
      "16       karniMGama        karnimgama               False               False   \n",
      "17               ne                ne               False               False   \n",
      "18  mahAparinirvANa   mahaparinirvana               False               False   \n",
      "19            mUrwi             murwi               False               False   \n",
      "20               kI                ki               False               False   \n",
      "21             Koja              koja                True               False   \n",
      "22               kI                ki               False               False   \n",
      "\n",
      "       -1_word_Stem    -1_word_Lemma          -2_word PrevToEnd   END  \n",
      "0               NaN              NaN              NaN       NaN   NaN  \n",
      "1              1876             1876              NaN       NaN   NaN  \n",
      "2               mem              meM             1876       NaN   NaN  \n",
      "3              yaha             yaha              meM       NaN   NaN  \n",
      "4             swana            sWAna             yaha       NaN   NaN  \n",
      "5               eka              eka            sWAna       NaN   NaN  \n",
      "6              bara             bAra              eka       NaN   NaN  \n",
      "7              pira             Pira             bAra       NaN   NaN  \n",
      "8           prakasa          prakASa             Pira       NaN   NaN  \n",
      "9               mem              meM          prakASa       NaN   NaN  \n",
      "10              aya              AyA              meM       NaN   NaN  \n",
      "11              \",\"              \",\"              AyA       NaN   NaN  \n",
      "12             jaba             jaba              \",\"       NaN   NaN  \n",
      "13        wawkalina        wawkAlIna             jaba       NaN   NaN  \n",
      "14   purawawvavewwa   purAwawvavewwA        wawkAlIna       NaN   NaN  \n",
      "15           loyrda           lOYrda   purAwawvavewwA       NaN   NaN  \n",
      "16       karnimgama       karniMGama           lOYrda       NaN   NaN  \n",
      "17               ne               ne       karniMGama       NaN   NaN  \n",
      "18  mahaparinirvana  mahAparinirvANa               ne       NaN   NaN  \n",
      "19            murwi            mUrwi  mahAparinirvANa       NaN   NaN  \n",
      "20               kI               kI            mUrwi       NaN   NaN  \n",
      "21             koja             Koja               kI      True   NaN  \n",
      "22               kI               kI             Koja      True  True  \n",
      "\n",
      "[23 rows x 29 columns]\n",
      "['PROPN', 'ADP', 'DET', 'NOUN', 'NUM', 'NOUN', 'ADV', 'NOUN', 'ADP', 'VERB', 'PUNCT', 'PRON', 'ADJ', 'NOUN', 'NOUN', 'PROPN', 'ADP', 'PROPN', 'PROPN', 'ADP', 'NOUN', 'VERB', 'PUNCT']\n"
     ]
    }
   ],
   "source": [
    "# print pre processed data\n",
    "print(len(X_train))           \n",
    "print(pd.DataFrame(X_train[5]))\n",
    "print(y_train[5], \"\\n\")\n",
    "\n",
    "print(len(X_test))           \n",
    "print(pd.DataFrame(X_test[5]))\n",
    "print(y_test[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 362
    },
    "id": "RSieB8Kh21FY",
    "outputId": "d0865ad5-e8a7-4f0c-a7f4-8e4ce505fe81",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CRF(algorithm='lbfgs', all_possible_transitions=True, c1=0.1, c2=0.1,\n",
       "    keep_tempfiles=None, max_iterations=100)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train with out hyper parameter optimization\n",
    "crf = sklearn_crfsuite.CRF(\n",
    "    algorithm='lbfgs',\n",
    "    c1=0.1,\n",
    "    c2=0.1,\n",
    "    max_iterations=100,\n",
    "    all_possible_transitions=True\n",
    ")\n",
    "crf.fit(X_train, y_train) # fit the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['DET', 'PROPN', 'ADP', 'ADV', 'ADJ', 'NOUN', 'NUM', 'AUX', 'PUNCT', 'PRON', 'VERB', 'CCONJ', 'PART', 'COMMA', 'SCONJ', 'X']\n"
     ]
    }
   ],
   "source": [
    "labels = list(crf.classes_) # extract labels from crf model \n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy, F1 Score on Train Set with out hyper parameter optimization:  0.9996051592524349 0.9996051006702492\n",
      "Accuracy, F1 Score on Test Set with out hyper parameter optimization:  0.8518005540166205 0.8511909604809106\n"
     ]
    }
   ],
   "source": [
    "y_pred_t = crf.predict(X_train)\n",
    "print(\"Accuracy, F1 Score on Train Set with out hyper parameter optimization: \", metrics.flat_accuracy_score(y_train, y_pred_t), metrics.flat_f1_score(y_train, y_pred_t, average='weighted', labels=labels))\n",
    "\n",
    "y_pred = crf.predict(X_test)\n",
    "print(\"Accuracy, F1 Score on Test Set with out hyper parameter optimization: \", metrics.flat_accuracy_score(y_test, y_pred), metrics.flat_f1_score(y_test, y_pred, average='weighted', labels=labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for Train Set :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           X      1.000     1.000     1.000         2\n",
      "        PART      1.000     1.000     1.000       163\n",
      "       CCONJ      1.000     1.000     1.000       150\n",
      "       SCONJ      1.000     1.000     1.000        61\n",
      "         ADJ      1.000     1.000     1.000       569\n",
      "         ADP      1.000     1.000     1.000      1384\n",
      "         ADV      1.000     1.000     1.000       110\n",
      "        VERB      1.000     0.995     0.998       639\n",
      "         DET      1.000     1.000     1.000       230\n",
      "       COMMA      1.000     1.000     1.000       114\n",
      "        NOUN      1.000     1.000     1.000      1596\n",
      "        PRON      1.000     1.000     1.000       430\n",
      "       PROPN      1.000     1.000     1.000       707\n",
      "         NUM      1.000     1.000     1.000       152\n",
      "       PUNCT      1.000     1.000     1.000       563\n",
      "         AUX      0.996     1.000     0.998       728\n",
      "\n",
      "    accuracy                          1.000      7598\n",
      "   macro avg      1.000     1.000     1.000      7598\n",
      "weighted avg      1.000     1.000     1.000      7598\n",
      "\n",
      "\n",
      "\n",
      "Metrics for Test Set :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           X      0.000     0.000     0.000         0\n",
      "        PART      1.000     0.909     0.952        33\n",
      "       CCONJ      1.000     1.000     1.000        25\n",
      "       SCONJ      0.750     1.000     0.857         3\n",
      "         ADJ      0.642     0.745     0.690        94\n",
      "         ADP      0.967     0.967     0.967       303\n",
      "         ADV      0.643     0.429     0.514        21\n",
      "        VERB      0.895     0.859     0.876        99\n",
      "         DET      0.842     0.889     0.865        36\n",
      "       COMMA      0.000     0.000     0.000         0\n",
      "        NOUN      0.787     0.880     0.831       324\n",
      "        PRON      0.806     0.831     0.818        65\n",
      "       PROPN      0.643     0.562     0.600       144\n",
      "         NUM      0.957     0.880     0.917        25\n",
      "       PUNCT      1.000     0.828     0.906       134\n",
      "         AUX      0.949     0.942     0.945       138\n",
      "\n",
      "   micro avg      0.852     0.852     0.852      1444\n",
      "   macro avg      0.743     0.733     0.734      1444\n",
      "weighted avg      0.855     0.852     0.851      1444\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# prediction, recall, f1 results for both test and train sets\n",
    "sorted_labels = sorted(\n",
    "    labels,\n",
    "    key=lambda name: (name[1:], name[0])\n",
    ")\n",
    "print(\"Metrics for Train Set :\\n\", metrics.flat_classification_report(\n",
    "    y_train, y_pred_t, labels=sorted_labels, digits=3\n",
    "))\n",
    "\n",
    "sorted_labels = sorted(\n",
    "    labels,\n",
    "    key=lambda name: (name[1:], name[0])\n",
    ")\n",
    "print(\"\\n\\nMetrics for Test Set :\\n\", metrics.flat_classification_report(\n",
    "    y_test, y_pred, labels=sorted_labels, digits=3\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top likely transitions with out hyper parameter optimization:\n",
      "VERB   -> AUX     4.064907\n",
      "PROPN  -> PROPN   2.651279\n",
      "ADJ    -> NOUN    2.504953\n",
      "NUM    -> NOUN    2.080024\n",
      "PROPN  -> ADP     2.045232\n",
      "AUX    -> AUX     2.043706\n",
      "DET    -> NOUN    1.876709\n",
      "PRON   -> ADP     1.678233\n",
      "NOUN   -> ADP     1.675150\n",
      "AUX    -> SCONJ   1.665517\n",
      "PART   -> NUM     1.510606\n",
      "VERB   -> SCONJ   1.371483\n",
      "PROPN  -> PUNCT   1.356431\n",
      "DET    -> ADJ     1.319981\n",
      "PROPN  -> CCONJ   1.249946\n",
      "ADV    -> VERB    1.171623\n",
      "CCONJ  -> PROPN   1.112683\n",
      "NOUN   -> CCONJ   1.025188\n",
      "NUM    -> NUM     0.998060\n",
      "ADJ    -> VERB    0.986983\n",
      "\n",
      "Top unlikely transitions with out hyper parameter optimization:\n",
      "NUM    -> PROPN   -0.758209\n",
      "PROPN  -> PART    -0.760037\n",
      "VERB   -> NUM     -0.787313\n",
      "AUX    -> ADP     -0.787440\n",
      "DET    -> CCONJ   -0.792342\n",
      "VERB   -> ADJ     -0.813883\n",
      "ADP    -> AUX     -0.830124\n",
      "VERB   -> VERB    -0.832582\n",
      "PRON   -> CCONJ   -0.865954\n",
      "NUM    -> PRON    -0.868445\n",
      "ADP    -> CCONJ   -0.905165\n",
      "PROPN  -> AUX     -0.907237\n",
      "CCONJ  -> AUX     -0.922118\n",
      "DET    -> PROPN   -0.927492\n",
      "AUX    -> VERB    -0.987564\n",
      "PROPN  -> DET     -1.004849\n",
      "AUX    -> ADJ     -1.065560\n",
      "ADJ    -> PRON    -1.692094\n",
      "DET    -> ADP     -1.726448\n",
      "ADJ    -> ADP     -1.761719\n"
     ]
    }
   ],
   "source": [
    "def print_transitions(trans_features):\n",
    "    for (label_from, label_to), weight in trans_features:\n",
    "        print(\"%-6s -> %-7s %0.6f\" % (label_from, label_to, weight))\n",
    "\n",
    "print(\"Top likely transitions with out hyper parameter optimization:\")\n",
    "print_transitions(Counter(crf.transition_features_).most_common(20))\n",
    "\n",
    "print(\"\\nTop unlikely transitions with out hyper parameter optimization:\")\n",
    "print_transitions(Counter(crf.transition_features_).most_common()[-20:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top positive features with out hyper parameter optimization:\n",
      "4.627470 NUM      IsDigit\n",
      "3.543670 ADJ      Suffix[-3:]:iwa\n",
      "3.257322 VERB     Suffix[-2:]:ne\n",
      "3.056400 NOUN     Suffix[-2:]:oM\n",
      "2.796039 PRON     Prefix[3:]:apa\n",
      "2.752691 PRON     Prefix[3:]:Apa\n",
      "2.730343 PRON     Prefix[2:]:Ap\n",
      "2.597030 PRON     Prefix[2:]:is\n",
      "2.513943 PRON     Prefix[2:]:ap\n",
      "2.497892 NOUN     bias\n",
      "\n",
      "Top negative features with out hyper parameter optimization:\n",
      "-1.126591 ADP      -2_word:nihArane\n",
      "-1.276119 NOUN     Prefix[2:]:ra\n",
      "-1.283902 X        bias\n",
      "-1.287043 CCONJ    +1:word_isuppercase\n",
      "-1.321439 AUX      -2_word:xeKane\n",
      "-1.332726 NOUN     Suffix[-3:]:Ina\n",
      "-1.346224 PROPN    IsTittleCase\n",
      "-1.449749 AUX      -2_word:jagaha\n",
      "-1.455890 PROPN    Suffix[-2:]:oM\n",
      "-1.555633 NOUN     IsDigit\n"
     ]
    }
   ],
   "source": [
    "def print_state_features(state_features):\n",
    "    for (attr, label), weight in state_features:\n",
    "        print(\"%0.6f %-8s %s\" % (weight, label, attr))\n",
    "\n",
    "print(\"Top positive features with out hyper parameter optimization:\")\n",
    "print_state_features(Counter(crf.state_features_).most_common(10))\n",
    "\n",
    "print(\"\\nTop negative features with out hyper parameter optimization:\")\n",
    "print_state_features(Counter(crf.state_features_).most_common()[-10:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 50 candidates, totalling 150 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 150 out of 150 | elapsed:  4.3min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3,\n",
       "                   estimator=CRF(algorithm='lbfgs',\n",
       "                                 all_possible_transitions=True,\n",
       "                                 keep_tempfiles=None, max_iterations=100),\n",
       "                   n_iter=50, n_jobs=-1,\n",
       "                   param_distributions={'c1': <scipy.stats._distn_infrastructure.rv_frozen object at 0x20100A70>,\n",
       "                                        'c2': <scipy.stats._distn_infrastructure.rv_frozen object at 0x20100BD0>},\n",
       "                   scoring=make_scorer(flat_f1_score, average=weighted, labels=['DET', 'PROPN', 'ADP', 'ADV', 'ADJ', 'NOUN', 'NUM', 'AUX', 'PUNCT', 'PRON', 'VERB', 'CCONJ', 'PART', 'COMMA', 'SCONJ', 'X']),\n",
       "                   verbose=1)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define fixed parameters and parameters to search\n",
    "crf = sklearn_crfsuite.CRF(\n",
    "    algorithm='lbfgs',\n",
    "    max_iterations=100,\n",
    "    all_possible_transitions=True\n",
    ")\n",
    "params_space = {\n",
    "    'c1': scipy.stats.expon(scale=0.5),\n",
    "    'c2': scipy.stats.expon(scale=0.05),\n",
    "}\n",
    "\n",
    "# use the same metric for evaluation\n",
    "f1_scorer = make_scorer(metrics.flat_f1_score,\n",
    "                        average='weighted', labels=labels)\n",
    "\n",
    "# randomized search for two hyperparameters\n",
    "rs = RandomizedSearchCV(crf, params_space,\n",
    "                        cv=3,\n",
    "                        verbose=1,\n",
    "                        n_jobs=-1,\n",
    "                        n_iter=50,\n",
    "                        scoring=f1_scorer)\n",
    "rs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy, F1 Score on Train Set with Hyperparameter Optimization:  0.9998683864174783 0.9998683800510951\n",
      "Accuracy, F1 Score on Test Set with Hyperparameter Optimization:  0.8587257617728532 0.857706394995462\n"
     ]
    }
   ],
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "y_pred_t = rs.predict(X_train)\n",
    "print(\"Accuracy, F1 Score on Train Set with Hyperparameter Optimization: \", metrics.flat_accuracy_score(y_train, y_pred_t), metrics.flat_f1_score(y_train, y_pred_t, average='weighted', labels=labels))\n",
    "warnings.filterwarnings('ignore')\n",
    "y_pred = rs.predict(X_test)\n",
    "print(\"Accuracy, F1 Score on Test Set with Hyperparameter Optimization: \", metrics.flat_accuracy_score(y_test, y_pred), metrics.flat_f1_score(y_test, y_pred, average='weighted', labels=labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for Train Set with Hyperparameter Optimization:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           X      1.000     1.000     1.000         2\n",
      "        PART      1.000     1.000     1.000       163\n",
      "       CCONJ      1.000     1.000     1.000       150\n",
      "       SCONJ      1.000     1.000     1.000        61\n",
      "         ADJ      1.000     1.000     1.000       569\n",
      "         ADP      1.000     1.000     1.000      1384\n",
      "         ADV      1.000     1.000     1.000       110\n",
      "        VERB      1.000     0.998     0.999       639\n",
      "         DET      1.000     1.000     1.000       230\n",
      "       COMMA      1.000     1.000     1.000       114\n",
      "        NOUN      1.000     1.000     1.000      1596\n",
      "        PRON      1.000     1.000     1.000       430\n",
      "       PROPN      1.000     1.000     1.000       707\n",
      "         NUM      1.000     1.000     1.000       152\n",
      "       PUNCT      1.000     1.000     1.000       563\n",
      "         AUX      0.999     1.000     0.999       728\n",
      "\n",
      "    accuracy                          1.000      7598\n",
      "   macro avg      1.000     1.000     1.000      7598\n",
      "weighted avg      1.000     1.000     1.000      7598\n",
      "\n",
      "\n",
      "\n",
      "Metrics for Test Set with Hyperparameter Optimization :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           X      0.000     0.000     0.000         0\n",
      "        PART      1.000     0.939     0.969        33\n",
      "       CCONJ      1.000     1.000     1.000        25\n",
      "       SCONJ      0.750     1.000     0.857         3\n",
      "         ADJ      0.658     0.777     0.712        94\n",
      "         ADP      0.964     0.970     0.967       303\n",
      "         ADV      0.643     0.429     0.514        21\n",
      "        VERB      0.904     0.859     0.881        99\n",
      "         DET      0.800     0.889     0.842        36\n",
      "       COMMA      0.000     0.000     0.000         0\n",
      "        NOUN      0.812     0.883     0.846       324\n",
      "        PRON      0.800     0.862     0.830        65\n",
      "       PROPN      0.648     0.562     0.602       144\n",
      "         NUM      0.958     0.920     0.939        25\n",
      "       PUNCT      1.000     0.828     0.906       134\n",
      "         AUX      0.949     0.949     0.949       138\n",
      "\n",
      "   micro avg      0.859     0.859     0.859      1444\n",
      "   macro avg      0.743     0.742     0.738      1444\n",
      "weighted avg      0.861     0.859     0.858      1444\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# prediction, recall, f1 results\n",
    "sorted_labels = sorted(\n",
    "    list(rs.classes_),\n",
    "    key=lambda name: (name[1:], name[0])\n",
    ")\n",
    "print(\"Metrics for Train Set with Hyperparameter Optimization:\\n\", metrics.flat_classification_report(\n",
    "    y_train, y_pred_t, labels=sorted_labels, digits=3\n",
    "))\n",
    "\n",
    "sorted_labels = sorted(\n",
    "    list(rs.classes_),\n",
    "    key=lambda name: (name[1:], name[0])\n",
    ")\n",
    "print(\"\\n\\nMetrics for Test Set with Hyperparameter Optimization :\\n\", metrics.flat_classification_report(\n",
    "    y_test, y_pred, labels=sorted_labels, digits=3\n",
    "))\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "NLP4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
